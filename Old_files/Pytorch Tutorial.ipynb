{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73738da-346c-4f6c-9ce8-3501a68d752c",
   "metadata": {},
   "source": [
    "# torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5850a-63f1-488a-99ea-d488e8a68219",
   "metadata": {},
   "source": [
    "#### 1. Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b485a6-813f-4f7c-becd-95ecb0b04b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#From Data: Creating a tensor from a list\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "#From NumPy Arrays\n",
    "np_array = np.array([[1, 2], [3, 4]])\n",
    "x = torch.from_numpy(np_array)\n",
    "\n",
    "# Using tensor\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "print(x.shape)\n",
    "\n",
    "# Zeros tensor \n",
    "zeros = torch.zeros(3, 3)\n",
    "\n",
    "# Ones tensor\n",
    "ones = torch.ones(2, 2)\n",
    "\n",
    "# Tensor random values\n",
    "rand = torch.rand(4, 4)\n",
    "\n",
    "# Tensor random values\n",
    "torch.manual_seed(132)\n",
    "rand = torch.rand(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99790c5f-041f-410c-9309-92a4d5d2b089",
   "metadata": {},
   "source": [
    "#### 2. Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea68df-2655-4a18-b498-a50c28007117",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "print(x.shape) \n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(x.dtype)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8536fe9a",
   "metadata": {},
   "source": [
    "#### Create similar tensor like one other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58638298",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.empty_like(x)\n",
    "\n",
    "torch.zeros_like(x)\n",
    "\n",
    "torch.ones_like(x)\n",
    "\n",
    "torch.rand_like(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126dd137-6a9e-41cb-90f5-7866bb7a3de9",
   "metadata": {},
   "source": [
    "#### 3. Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0291dbe-5863-495c-9100-caa910ba7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Select a specific element\n",
    "element = x[1, 2]  # Output: 6\n",
    "\n",
    "# Select a specific row\n",
    "row = x[0, :]  # Output: tensor([1, 2, 3])\n",
    "\n",
    "# Select a specific column\n",
    "column = x[:, 1]  # Output: tensor([2, 5, 8])\n",
    "\n",
    "# Slices rows 0 to 1 and columns 1 to 2\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "sub_tensor = x[0:2, 1:3]  \n",
    "print(sub_tensor)  # Output: tensor([[2, 3], [5, 6]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42225c-1cff-4cee-9270-76b2c7e3221a",
   "metadata": {},
   "source": [
    "#### 4. Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9a2ec-3b82-441c-aafe-5139c2288c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view: view is one of the most commonly used methods for reshaping tensors. It returns a new tensor with the same data but a different shape\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = x.view(3, 2)  # Reshape to 3x2\n",
    "print(y)\n",
    "\n",
    "# reshape: Similar to view, but more flexible as it can handle cases where the tensor is not contiguous \n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = x.reshape(3, 2)  # Reshape to 3x2\n",
    "print(y)\n",
    "\n",
    "# squeeze: Removes dimensions of size 1 from the tensor.\n",
    "x = torch.tensor([[[1], [2], [3]]])\n",
    "y = x.squeeze()  # Removes the extra dimensions\n",
    "print(y)\n",
    "\n",
    "# unsqueeze: Adds a dimension of size 1 at the specified position.\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = x.unsqueeze(0)  # Adds a new dimension at position 0\n",
    "print(y)\n",
    "\n",
    "# transpose: Make the rows into columns and columns into rows\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = x.transpose(0, 1)  # Swaps dimension 0 and 1\n",
    "print(y)\n",
    "\n",
    "# flatten: Flattens the tensor into a one-dimensional tensor. Optionally, you can specify the start and end dimensions to flatten.\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = x.flatten()  # Flattens to 1D tensor\n",
    "print(y)\n",
    "\n",
    "# stack: Stacks a sequence of tensors along a new dimension.\n",
    "x1 = torch.tensor([1, 2])\n",
    "x2 = torch.tensor([3, 4])\n",
    "y = torch.stack((x1, x2), dim=0)  # Stacks along a new dimension\n",
    "print(y)\n",
    "\n",
    "# Concatenation: \n",
    "x1 = torch.tensor([[1, 2], [3, 4]])\n",
    "x2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "x_cat = torch.cat((x1, x2), dim=0)  # Concatenate along rows\n",
    "x_cat = torch.cat((x1, x2), dim=1)  # Concatenate along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef170ff-9c90-4cc3-a8a5-30b832f0e3b2",
   "metadata": {},
   "source": [
    "#### 5.Element-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea73462-b787-4beb-b8be-9b4f66fd6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "z = x + y  # Addition\n",
    "z = x * y  # Multiplication\n",
    "z = x / y  # Division\n",
    "\n",
    "result = a.add(b)  # Addition\n",
    "result = a.sub(b)  # Subtraction\n",
    "result = a.mul(b)  # Multiplication\n",
    "result = a.div(b)  # Division\n",
    "\n",
    "# int division\n",
    "(x * 100)//3\n",
    "# mod\n",
    "((x * 100)//3)%2\n",
    "# power\n",
    "x**2\n",
    "\n",
    "######################################################################\n",
    "######################################################################\n",
    "c = torch.tensor([1, -2, 3, -4])\n",
    "# abs\n",
    "torch.abs(c)\n",
    "\n",
    "# negative\n",
    "torch.neg(c)\n",
    "\n",
    "######################################################################\n",
    "######################################################################\n",
    "d = torch.tensor([1.9, 2.3, 3.7, 4.4])\n",
    "\n",
    "# round\n",
    "torch.round(d)\n",
    "\n",
    "# ceil\n",
    "torch.ceil(d)\n",
    "\n",
    "# floor\n",
    "torch.floor(d)\n",
    "\n",
    "# clamp\n",
    "torch.clamp(d, min=2, max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ece421-e763-40b3-8dbc-ceb930fc6d64",
   "metadata": {},
   "source": [
    "#### 6. Casting and Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0260668-d7c0-49b4-aa23-4a37c488769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x_int = x.int()  # Convert to integer type\n",
    "x_float = x.float()  # Convert back to float\n",
    "\n",
    "# Type Conversion\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "x = x.to(torch.float32)  # Convert to float\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95425a0e-0072-42ce-97ef-81990b4e61ed",
   "metadata": {},
   "source": [
    "#### 7. Broadcasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9b01b-f299-4a3b-9993-c57d4677d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([[1], [2], [3]])\n",
    "z = x + y  # Broadcasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97335005-b224-4d1b-b604-b21166fb54ec",
   "metadata": {},
   "source": [
    "#### 8. Device Management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f3dc2-a373-4e74-80be-c48a405d4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensors between CPU and GPU.\n",
    "x_cpu = torch.tensor([1.0, 2.0])\n",
    "x_gpu = x_cpu.to('cuda')  # Move to GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05799e-e648-420f-a7f2-08ee10ce352a",
   "metadata": {},
   "source": [
    "#### 9. Saving and Loading Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb49a18-c53c-4c49-b840-a5f9d36344ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x, 'tensor.pt')\n",
    "x = torch.load('tensor.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7c409",
   "metadata": {},
   "source": [
    "#### 10. Tensor Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249fa488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.linspace: Creates a tensor with evenly spaced values between start and end\n",
    "x = torch.linspace(0, 10, steps=5)  # 5 points between 0 and 10 (inclusive)\n",
    "print(x)\n",
    "\n",
    "# torch.arange: Creates a tensor with a range of values and a specific step\n",
    "y = torch.arange(0, 10, step=2)  # Values from 0 to 10 with a step of 2\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9b424",
   "metadata": {},
   "source": [
    "#### 11. Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.eye: Creates a 2D identity matrix\n",
    "identity = torch.eye(3)  # 3x3 identity matrix\n",
    "print(identity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf6fa8",
   "metadata": {},
   "source": [
    "#### Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba26a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn: Creates a tensor with random numbers sampled from a normal distribution\n",
    "random_tensor = torch.randn(3, 3)\n",
    "print(random_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84c95b",
   "metadata": {},
   "source": [
    "#### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################   Reduction Operations ######################################\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Sum, Mean\n",
    "print(x.sum())  # Sum of all elements\n",
    "print(x.mean())  # Mean of all elements\n",
    "\n",
    "# Max, Min, Argmax, Argmin\n",
    "print(x.max())  # Maximum value\n",
    "print(x.argmax())  # Index of maximum value (flattened tensor)\n",
    "print(x.min())  # Minimum value\n",
    "print(x.argmin())  # Index of minimum value (flattened tensor)\n",
    "\n",
    "#########################################################  Matrix Multiplication ##############################################\n",
    "# Matrix multiplication using @ and torch.matmul\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Both produce the same result\n",
    "result = a @ b\n",
    "print(result)\n",
    "\n",
    "result = torch.matmul(a, b)\n",
    "print(result)\n",
    "\n",
    "\n",
    "############################################################### In-place Operations  #############################################\n",
    "# Example of in-place addition\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x.add_(1.0)  # Adds 1 to each element in-place\n",
    "print(x)\n",
    "\n",
    "# Note: In-place operations modify the tensor directly and end with an underscore (_).\n",
    "# Be cautious as they can affect computation graphs if gradients are used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928e0e6",
   "metadata": {},
   "source": [
    " #### Advanced Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Boolean Indexing ##############################################\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# Boolean indexing: Select values greater than 3\n",
    "mask = x > 3\n",
    "filtered = x[mask]\n",
    "print(filtered)  # Output: tensor([4, 5])\n",
    "\n",
    "############################################## Fancy Indexing  #################################################\n",
    "\n",
    "\n",
    "x = torch.tensor([10, 20, 30, 40, 50])\n",
    "\n",
    "# Fancy indexing with a tensor of indices\n",
    "indices = torch.tensor([0, 3, 4])\n",
    "selected = x[indices]\n",
    "print(selected)  # Output: tensor([10, 40, 50])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200a8d4",
   "metadata": {},
   "source": [
    "#### Gradient Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform some operations\n",
    "y = x ** 2 + 3\n",
    "\n",
    "# Compute gradients\n",
    "y.sum().backward()\n",
    "print(x.grad)  # Gradients of y with respect to x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9ca98",
   "metadata": {},
   "source": [
    "#### Tensor Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# Clone creates a copy of the tensor\n",
    "y = x.clone()\n",
    "y[0, 0] = 99  # Modify y\n",
    "print(x)  # Original tensor remains unchanged\n",
    "print(y)  # Modified tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780a324",
   "metadata": {},
   "source": [
    "#### Contiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f456f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = x.t()  # Transpose makes the tensor non-contiguous\n",
    "print(y.is_contiguous())  # False\n",
    "\n",
    "# Make it contiguous\n",
    "y = y.contiguous()\n",
    "print(y.is_contiguous())  # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1e308",
   "metadata": {},
   "source": [
    "#### Other Tensor Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Expand: Repeat the same data without copying\n",
    "expanded = x.unsqueeze(1).expand(3, 3)\n",
    "print(expanded)\n",
    "\n",
    "# Repeat: Repeat the data by copying it\n",
    "repeated = x.repeat(3, 1)\n",
    "print(repeated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebff1f8",
   "metadata": {},
   "source": [
    "#### Chunk and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03580b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Split into 3 chunks\n",
    "chunks = torch.chunk(x, 3)\n",
    "print(chunks)\n",
    "\n",
    "# Split into parts of size 2\n",
    "splits = torch.split(x, 2)\n",
    "print(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285a7ee",
   "metadata": {},
   "source": [
    "#### Random Number Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a manual seed ensures reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a random tensor\n",
    "random_tensor = torch.rand(3, 3)\n",
    "print(random_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9fc1e",
   "metadata": {},
   "source": [
    "#### Gradient Tracking (Basic Autograd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with gradient tracking\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform operations\n",
    "y = x[0] ** 2 + 2 * x[1]\n",
    "\n",
    "# Compute gradients\n",
    "y.backward()\n",
    "print(x.grad)  # Gradients of y with respect to x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc5496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30633b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124b332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd3671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e94b6e8a-6b29-4790-96ce-2b8b2645c786",
   "metadata": {},
   "source": [
    "# torch.nn Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd95de-cdec-4ec6-a382-e06c8432b68b",
   "metadata": {},
   "source": [
    "### Core Layers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595913e-816f-4e1b-90ae-8730027d76d3",
   "metadata": {},
   "source": [
    "#### nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b7a05-98e9-49b4-a4a2-ef5960f5a7bc",
   "metadata": {},
   "source": [
    "The nn.Linear layer applies a linear transformation to the incoming data: y= xA<sub>T<sub>+b It is commonly used in fully connected (dense) layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31897ac0-6891-4b46-9252-4d7558bb5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "output = linear(input_tensor)  # input_tensor should be of shape [batch_size, 128]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72b374-664a-4105-b1d6-d0e03903db4e",
   "metadata": {},
   "source": [
    "#### nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f7f8d-e875-4072-a309-a6de3b1b80c5",
   "metadata": {},
   "source": [
    "The nn.Conv2d layer applies a 2D convolution over an input signal composed of several input planes (e.g., an image). It's typically used for image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897e8e1-fe4f-414d-a88a-5ac70f6b036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "output = conv(input_tensor)  # input_tensor should be of shape [batch_size, 3, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9faa72-fec0-484a-bea0-b106dfa61878",
   "metadata": {},
   "source": [
    "#### 3. nn.Conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42e7ad-d569-49d2-83db-0c6b35d677ca",
   "metadata": {},
   "source": [
    "The nn.Conv1d layer applies a 1D convolution over an input signal composed of several input planes (e.g., time-series data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf1793-8909-491e-941c-78e7da312c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "output = conv1d(input_tensor)  # input_tensor should be of shape [batch_size, 1, sequence_length]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5602c-2bb3-4a2d-9421-b56c35d530d0",
   "metadata": {},
   "source": [
    "#### nn.Conv3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff624a2-18ed-457a-9beb-50294c51466c",
   "metadata": {},
   "source": [
    "The nn.Conv3d layer applies a 3D convolution over an input signal composed of several input planes (e.g., volumetric data like MRI scans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea58b86-6574-4ef1-b02a-80cd319f5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3d = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "output = conv3d(input_tensor)  # input_tensor should be of shape [batch_size, 1, depth, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ee32b-82cc-4148-b1c1-5ac85e75c8b8",
   "metadata": {},
   "source": [
    "#### nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65fcae-dfe6-4925-826c-4469a22c2332",
   "metadata": {},
   "source": [
    "The nn.MaxPool2d layer applies a 2D max pooling operation over an input signal, which reduces its spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af7f6b-ccc5-41ae-9244-20f887d51f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "output = maxpool(input_tensor)  # input_tensor should be of shape [batch_size, channels, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4c612-34e7-4d3b-8432-baee9fb82e91",
   "metadata": {},
   "source": [
    "#### nn.AvgPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70af446-fd8c-444a-ab21-444fbf05600c",
   "metadata": {},
   "source": [
    "The nn.AvgPool2d layer applies a 2D average pooling operation over an input signal, which also reduces its spatial dimensions by averaging the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48359ff-3648-4d9d-8331-291ad90a5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "output = avgpool(input_tensor)  # input_tensor should be of shape [batch_size, channels, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1859064-8cfd-46f5-a804-39bf9a7ed830",
   "metadata": {},
   "source": [
    "#### nn.MaxPool1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4241f8-fc37-4f94-be7f-85399bfe8cb8",
   "metadata": {},
   "source": [
    "The nn.MaxPool1d layer applies a 1D max pooling operation, commonly used for sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b37ea-6802-499c-a078-8b1d94092e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool1d = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "output = maxpool1d(input_tensor)  # input_tensor should be of shape [batch_size, channels, sequence_length]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59d9db-f4e3-46a5-b1cb-3bcb21e7edda",
   "metadata": {},
   "source": [
    "#### nn.AvgPool1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696dcde-ae02-42d5-9680-b9900ef73f85",
   "metadata": {},
   "source": [
    "The nn.AvgPool1d layer applies a 1D average pooling operation, commonly used for sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c69ff-a233-4359-9053-928045514f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool1d = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "output = avgpool1d(input_tensor)  # input_tensor should be of shape [batch_size, channels, sequence_length]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d604a-f194-442f-9431-aea61c6d0210",
   "metadata": {},
   "source": [
    "#### nn.RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223706c-d73e-4882-941a-1f190c6f5758",
   "metadata": {},
   "source": [
    "The nn.RNN layer is a basic recurrent neural network layer that processes sequential data by maintaining hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528e00f-aab2-4258-9618-11a96c49f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "output, hn = rnn(input_tensor)  # input_tensor should be of shape [batch_size, sequence_length, input_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de19256-19a5-4565-9f60-d6dbce5ea798",
   "metadata": {},
   "source": [
    "#### nn.LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb3e0b-a2a8-469d-bf4d-7a2e1326fe4f",
   "metadata": {},
   "source": [
    "The nn.LSTM layer is an advanced recurrent neural network layer that mitigates the vanishing gradient problem, making it effective for longer sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d257791-9df9-4854-9d18-5fa7ff19d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "output, (hn, cn) = lstm(input_tensor)  # input_tensor should be of shape [batch_size, sequence_length, input_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6635d-94bd-4458-8eaa-593919190d32",
   "metadata": {},
   "source": [
    "#### nn.GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2d755-77ef-4c23-a310-c05e8fe18c70",
   "metadata": {},
   "source": [
    "The nn.GRU layer is a variant of the LSTM layer, with a simpler structure but often similar performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc5622-7a7e-4774-8f40-d67f882fa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "output, hn = gru(input_tensor)  # input_tensor should be of shape [batch_size, sequence_length, input_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b0de0-9e06-4073-8592-3abc4826348e",
   "metadata": {},
   "source": [
    "#### nn.BatchNorm1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c277b60-e4c9-4419-8ce1-3e2dcae01d8d",
   "metadata": {},
   "source": [
    "The nn.BatchNorm1d layer normalizes the input to a layer for each mini-batch, stabilizing learning in fully connected layers or 1D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8fe091-eead-4785-a0b4-16dc3162710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm1d = nn.BatchNorm1d(num_features=128)\n",
    "output = batchnorm1d(input_tensor)  # input_tensor should be of shape [batch_size, num_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07975497-59b2-45f7-a73b-63c5785d26ef",
   "metadata": {},
   "source": [
    "#### nn.BatchNorm2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c8550-b00a-4398-be0d-fa9fcb82ec89",
   "metadata": {},
   "source": [
    "The nn.BatchNorm2d layer normalizes the input for 2D data, such as images, stabilizing learning and improving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d30b3-e997-48b4-beaa-5a35f022e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm2d = nn.BatchNorm2d(num_features=16)\n",
    "output = batchnorm2d(input_tensor)  # input_tensor should be of shape [batch_size, num_features, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39d036-aea8-4802-a1e2-0194d957fd46",
   "metadata": {},
   "source": [
    "#### nn.BatchNorm3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83bc7a2-21b9-4c3b-967a-d079c00f2b0f",
   "metadata": {},
   "source": [
    "The nn.BatchNorm3d layer normalizes the input for 3D data, such as volumetric scans, stabilizing learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f75b73-0045-44b4-8c18-f9c783c6cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm3d = nn.BatchNorm3d(num_features=16)\n",
    "output = batchnorm3d(input_tensor)  # input_tensor should be of shape [batch_size, num_features, depth, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb81a8e-6a43-4e21-85a0-701e7a234ae0",
   "metadata": {},
   "source": [
    "#### nn.Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc79df1-a1fc-41d2-b02a-dd3f0572043e",
   "metadata": {},
   "source": [
    "The nn.Dropout layer randomly zeroes some of the elements of the input tensor with a given probability during training, which helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa50ec-b102-4335-862a-0a36203d7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=0.5)\n",
    "output = dropout(input_tensor)  # input_tensor shape remains unchanged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f4d0e-e462-47f9-8c84-ddaffec50b36",
   "metadata": {},
   "source": [
    "#### nn.Dropout2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aab96d-3be7-43a1-8d84-47741af8d23d",
   "metadata": {},
   "source": [
    "The nn.Dropout2d layer randomly zeroes entire channels (a.k.a. feature maps) of 2D inputs, which is commonly used with image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8903c11-2346-4dc9-8e15-ce84aa858222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout2d = nn.Dropout2d(p=0.5)\n",
    "output = dropout2d(input_tensor)  # input_tensor should be of shape [batch_size, channels, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23a072-7af4-4030-a55c-dfc3b1d8aac2",
   "metadata": {},
   "source": [
    "#### nn.Dropout3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ded23-6778-402f-81cc-7b37dacaba6d",
   "metadata": {},
   "source": [
    "The nn.Dropout3d layer randomly zeroes entire channels of 3D inputs, commonly used with volumetric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16693e-96ec-42f6-8f60-b57936868b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout3d = nn.Dropout3d(p=0.5)\n",
    "output = dropout3d(input_tensor)  # input_tensor should be of shape [batch_size, channels, depth, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b4c5d-bdf2-419c-a805-bd4073665381",
   "metadata": {},
   "source": [
    "#### nn.Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6fb32-0778-458d-9146-24edb1c6d973",
   "metadata": {},
   "source": [
    "The nn.Embedding layer maps indices of categorical variables (e.g., words) to dense vectors, often used in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0f0e2-ebc9-4e3a-b3ee-bfa796599ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=1000, embedding_dim=50)\n",
    "output = embedding(input_tensor)  # input_tensor should be of shape [batch_size, sequence_length]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43c1db-c4fd-46b3-bcd3-25dc8946adcd",
   "metadata": {},
   "source": [
    "#### nn.Sequential "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f9e38-6964-400f-b30a-541d2c7cd957",
   "metadata": {},
   "source": [
    "The nn.Sequential container allows you to define a model by stacking layers in a sequential manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd1a75-3f76-42ba-bc28-ad6959adddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "output = model(input_tensor)  # input_tensor should be of shape [batch_size, 128]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c256c-2886-4822-b322-cbef53d0cea7",
   "metadata": {},
   "source": [
    "#### nn.Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e0fc7-08c0-495d-a3d0-58581dcb2db6",
   "metadata": {},
   "source": [
    "The nn.Flatten layer reshapes the input tensor to 2D, typically used before fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7081c17-3333-496f-861e-8aa9f0a9d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "output = flatten(input_tensor)  # input_tensor will be flattened to shape [batch_size, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458237b-c378-47a7-9c05-77c5ec2277e4",
   "metadata": {},
   "source": [
    "#### nn.Unflatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55acd2e-6342-4c56-8860-a40739d95d9f",
   "metadata": {},
   "source": [
    "The nn.Unflatten layer reshapes a flattened tensor back to a desired shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef87f30-c34f-4ddf-b170-b517355bddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unflatten = nn.Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
    "output = unflatten(input_tensor)  # input_tensor will be reshaped to [batch_size, 16, 32, 32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fb13b-2d43-4031-9cce-51f1d3e77fd8",
   "metadata": {},
   "source": [
    "### Advanced Layers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a947fb-c346-44a7-9c4e-7044cfa02756",
   "metadata": {},
   "source": [
    "#### nn.MultiheadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8898bf-d62a-4e18-b12d-345457296601",
   "metadata": {},
   "source": [
    "Purpose: nn.MultiheadAttention is a key component in Transformer models, allowing the model to focus on different parts of the input sequence simultaneously (multi-head attention). It applies the attention mechanism to the input sequences, which is crucial for tasks like machine translation, text generation, and more.\n",
    "\n",
    "Inputs:\n",
    "Query (query): The sequence of vectors for which the attention is computed.\n",
    "Key (key): The sequence of vectors over which the attention is computed.\n",
    "Value (value): The sequence of vectors from which the final attended vectors are computed.\n",
    "These can all be the same sequence in self-attention.\n",
    "\n",
    "Output: A tensor where each position has attended to other positions in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29623777-3689-460c-832d-78d1a4d55a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the multi-head attention layer\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "\n",
    "# Example input tensors (sequence length of 50, batch size of 32, embedding dimension of 512)\n",
    "query = torch.randn(50, 32, 512)  # [sequence length, batch size, embedding dimension]\n",
    "key = torch.randn(50, 32, 512)    # Usually the same as query in self-attention\n",
    "value = torch.randn(50, 32, 512)  # Usually the same as key in self-attention\n",
    "\n",
    "# Apply multi-head attention\n",
    "attn_output, attn_weights = multihead_attn(query, key, value)\n",
    "\n",
    "# Output shapes:\n",
    "print(attn_output.shape)  # [50, 32, 512] - Same as input shape\n",
    "print(attn_weights.shape) # [32, 8, 50, 50] - Attention weights across heads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96741b3e-da35-4f51-97cf-51fda33449c3",
   "metadata": {},
   "source": [
    "#### nn.PixelShuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefa235-379c-4d79-be77-22791a02ac33",
   "metadata": {},
   "source": [
    "Purpose: nn.PixelShuffle is used in tasks like image super-resolution. It rearranges elements in a tensor of shape [*, C*r^2, H, W] to a tensor of shape [*, C, H*r, W*r], where r is the upscale factor. This effectively increases the spatial resolution of the image by moving information from the channel dimension to the spatial dimensions.\n",
    "Input: A tensor where the channels contain sub-pixels of the high-resolution image.\n",
    "Output: A tensor with increased spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b013c-41d5-4e74-870b-1da0f010818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the pixel shuffle layer with an upscale factor of 2\n",
    "pixel_shuffle = nn.PixelShuffle(upscale_factor=2)\n",
    "\n",
    "# Example input tensor with shape [batch_size, C*r^2, H, W]\n",
    "# For example, with a batch size of 32, 64 channels, 16x16 image, and upscale factor of 2:\n",
    "input_tensor = torch.randn(32, 64, 16, 16)  # Here, C*r^2 = 64 and r = 2, so C = 16\n",
    "\n",
    "# Apply pixel shuffle\n",
    "output_tensor = pixel_shuffle(input_tensor)\n",
    "\n",
    "# Output shape:\n",
    "print(output_tensor.shape)  # Should be [32, 16, 32, 32] - (Batch size, C, H*r, W*r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62747647-32c1-4371-bfef-b327136da57c",
   "metadata": {},
   "source": [
    "### Loss Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210cbfc-34f8-4b2f-a6df-e18378038352",
   "metadata": {},
   "source": [
    "#### nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f853cdc-afe6-4d7e-af93-917d3ab13e61",
   "metadata": {},
   "source": [
    "Purpose: nn.CrossEntropyLoss is used for multi-class classification problems. It combines LogSoftmax and NLLLoss in one step. This loss function expects raw logits as input, not probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e3dbb-d113-4334-a467-5493680f085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear layer and loss function\n",
    "linear = nn.Linear(in_features=128, out_features=10)  # 10 classes output\n",
    "input_tensor = torch.randn(32, 128)  # Batch size of 32, 128 features\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Define CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Example target (ground truth labels)\n",
    "target = torch.randint(0, 10, (32,))  # Randomly generated target with 10 classes\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f145e04-004f-49b9-adb5-53079bde08aa",
   "metadata": {},
   "source": [
    "#### nn.MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936694f-6cd1-4d93-9d17-bfb06f0cf458",
   "metadata": {},
   "source": [
    "Purpose: nn.MSELoss (Mean Squared Error Loss) is used for regression tasks where the goal is to minimize the squared difference between predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a9ccd-28e3-4961-ba57-bc09463f6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear layer and loss function\n",
    "linear = nn.Linear(in_features=128, out_features=1)  # Single output for regression\n",
    "input_tensor = torch.randn(32, 128)  # Batch size of 32, 128 features\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Define MSELoss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Example target (ground truth values)\n",
    "target = torch.randn(32, 1)  # Ground truth values with the same shape as output\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af6bd1-2a06-4b9e-ae20-86b89a421210",
   "metadata": {},
   "source": [
    "#### nn.BCELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66fd1c-546c-4fa5-9af7-f87fd4f25583",
   "metadata": {},
   "source": [
    "Purpose: nn.BCELoss (Binary Cross-Entropy Loss) is used for binary classification tasks. It measures the difference between the predicted probabilities and the actual class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be819a-fdb8-4cec-adab-94f7a300a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear layer and sigmoid activation for binary classification\n",
    "linear = nn.Linear(in_features=128, out_features=1)  # Single output for binary classification\n",
    "input_tensor = torch.randn(32, 128)  # Batch size of 32, 128 features\n",
    "output = torch.sigmoid(linear(input_tensor))  # Apply sigmoid to get probabilities\n",
    "\n",
    "# Define BCELoss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Example target (ground truth binary labels)\n",
    "target = torch.randint(0, 2, (32, 1)).float()  # Binary labels (0 or 1)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbd8ca-6378-4727-8ee1-1dca4aa2fce8",
   "metadata": {},
   "source": [
    "#### nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7a25d-ad11-490d-a43f-ee591e9008f2",
   "metadata": {},
   "source": [
    "Purpose: nn.BCEWithLogitsLoss is similar to nn.BCELoss, but it combines the sigmoid layer and binary cross-entropy loss into one step. This is more numerically stable than using nn.BCELoss with a separate sigmoid layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dec4d8-da16-4e74-926b-a414d5fb955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear layer for binary classification\n",
    "linear = nn.Linear(in_features=128, out_features=1)  # Single output for binary classification\n",
    "input_tensor = torch.randn(32, 128)  # Batch size of 32, 128 features\n",
    "output = linear(input_tensor)  # No sigmoid applied\n",
    "\n",
    "# Define BCEWithLogitsLoss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Example target (ground truth binary labels)\n",
    "target = torch.randint(0, 2, (32, 1)).float()  # Binary labels (0 or 1)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87dec9-3fa1-4f80-9c75-8f34cc1ad5b4",
   "metadata": {},
   "source": [
    "#### nn.L1Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fdd3a6-270b-4b99-ac19-cea419c82c09",
   "metadata": {},
   "source": [
    "Purpose: nn.L1Loss (Mean Absolute Error Loss) is used to minimize the absolute differences between the predicted values and the actual values. This loss function is more robust to outliers than MSELoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106b0e6-8c63-4f85-9377-274493f9cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear layer and loss function\n",
    "linear = nn.Linear(in_features=128, out_features=1)  # Single output for regression\n",
    "input_tensor = torch.randn(32, 128)  # Batch size of 32, 128 features\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Define L1Loss\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Example target (ground truth values)\n",
    "target = torch.randn(32, 1)  # Ground truth values with the same shape as output\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b03235-c3fb-4374-aea0-1ac838201e70",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57641ebd-8a33-4977-abe4-5d6a18bf25e5",
   "metadata": {},
   "source": [
    "#### torch.optim.SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fb579-9c48-4609-9ce9-0145f8f2ff3d",
   "metadata": {},
   "source": [
    "SGD is one of the simplest and most widely used optimization algorithms. It updates the model's parameters by moving them in the direction opposite to the gradient of the loss function. You can also add momentum to the updates to accelerate convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b75ce-5bbd-472e-9b3d-9083fabb0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple linear layer\n",
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "\n",
    "# Create an optimizer using SGD with learning rate and momentum\n",
    "optimizer = optim.SGD(linear.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Example input tensor\n",
    "input_tensor = torch.randn(32, 128)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Assume we have a loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "target = torch.randn(32, 64)\n",
    "loss = loss_fn(output, target)\n",
    "\n",
    "# Backward pass and optimization step\n",
    "loss.backward()  # Compute gradients\n",
    "optimizer.step()  # Update parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118749b5-9474-4355-bbd1-68316ce3f799",
   "metadata": {},
   "source": [
    "#### torch.optim.Adam "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3a434-58d5-4f37-ae75-42f5ea6233e1",
   "metadata": {},
   "source": [
    "Adam is an adaptive learning rate optimizer that computes individual learning rates for each parameter based on the first and second moments of the gradients. It is widely used due to its efficiency and effectiveness, particularly in training deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213fdb0c-ed9d-423f-af8a-ee02a38ab0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer using Adam\n",
    "optimizer = optim.Adam(linear.parameters(), lr=0.001)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Loss and backward pass\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Optimization step\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b93e24-cffe-40fd-9704-a7905623c1f3",
   "metadata": {},
   "source": [
    "#### torch.optim.RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e29eb-8d5b-4b8f-87e7-d08ce08844e0",
   "metadata": {},
   "source": [
    "RMSprop is another adaptive learning rate optimizer, designed to mitigate the problem of vanishing and exploding gradients. It maintains a moving average of the squared gradients to normalize the gradient itself, which helps in achieving more stable updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e075c-60b7-4b5a-bf32-b9e49edd8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer using RMSprop\n",
    "optimizer = optim.RMSprop(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Loss and backward pass\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Optimization step\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302a1dd-b2c8-45bb-8b38-d501c84a6dc6",
   "metadata": {},
   "source": [
    "#### torch.optim.AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8c598-e4b0-4ab3-bb93-1083dc92dda6",
   "metadata": {},
   "source": [
    "AdamW is a variant of Adam that decouples weight decay (used for regularization) from the gradient updates. This approach often leads to better generalization in deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe84fc2-ff2c-435a-8973-10568b05ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer using AdamW with weight decay\n",
    "optimizer = optim.AdamW(linear.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Loss and backward pass\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Optimization step\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2b336-f4e8-41c6-832b-a610705fadd3",
   "metadata": {},
   "source": [
    "#### torch.optim.Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4898b84-eef3-4ca5-8c0c-aa12c58cf732",
   "metadata": {},
   "source": [
    "Adagrad adapts the learning rate for each parameter by scaling it inversely proportional to the sum of the squares of all previous gradients. This helps in dealing with sparse data and parameters that require frequent updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8c37b-df38-4b52-8faf-9e8f22eacdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer using Adagrad\n",
    "optimizer = optim.Adagrad(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Loss and backward pass\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Optimization step\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bc5c0-f8c8-431d-bdb4-087649c8d888",
   "metadata": {},
   "source": [
    "#### torch.optim.Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08f53b-9cb3-4648-8119-1cd230aef3b6",
   "metadata": {},
   "source": [
    " Adamax is a variant of Adam based on the infinity norm (max-norm). It is more robust to very large gradients and can provide better performance in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d41d4-4bd2-4d5e-9cd0-451fab42a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer using Adamax\n",
    "optimizer = optim.Adamax(linear.parameters(), lr=0.002)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Loss and backward pass\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Optimization step\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a68d3d-2e2d-4804-9b46-2a7715a5e03e",
   "metadata": {},
   "source": [
    "#### torch.optim.NAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f572e4-d7ef-4c51-86a8-4167cafa8797",
   "metadata": {},
   "source": [
    "NAdam combines Adam with Nesterov momentum, which can lead to faster convergence in some cases by anticipating the direction of the future gradient based on the current momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b665e92-a603-442c-9619-0957b85d8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer using NAdam\n",
    "optimizer = optim.NAdam(linear.parameters(), lr=0.002)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n",
    "\n",
    "# Loss and backward pass\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Optimization step\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c7923-7b0e-4e4d-8129-989cd2ddbb90",
   "metadata": {},
   "source": [
    "### Learning Rate Schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4af78-2414-48bb-87c9-3627e1f09ad9",
   "metadata": {},
   "source": [
    "#### StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762d5ee-fae9-4ce2-8dab-8e7e0f796e45",
   "metadata": {},
   "source": [
    "StepLR decreases the learning rate of each parameter group by a factor of gamma every step_size epochs. This is useful when you want to reduce the learning rate at regular intervals during training to allow the model to settle into a local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb76c1-3490-46c9-85a1-e93c350bf13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example model and optimizer\n",
    "model = nn.Linear(in_features=128, out_features=64)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# StepLR scheduler: Reduces learning rate by a factor of 0.1 every 10 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(30):\n",
    "    # Training code...\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Learning rate is {scheduler.get_last_lr()[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f97db6-b5e2-4614-aa78-dace24a4a104",
   "metadata": {},
   "source": [
    "#### ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df625f-69f9-4750-b66e-78b56558799a",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau reduces the learning rate when a metric has stopped improving. This scheduler is useful for scenarios where the learning rate should be reduced if the model's performance plateaus, allowing the model to converge more slowly to avoid overshooting the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fe802-ba90-43fc-91a1-ccb430408ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example model and optimizer\n",
    "model = nn.Linear(in_features=128, out_features=64)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# ReduceLROnPlateau scheduler: Reduces learning rate by a factor of 0.1 if the validation loss stops improving\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(30):\n",
    "    # Training code...\n",
    "    \n",
    "    # Assume val_loss is computed after each epoch\n",
    "    val_loss = 0.1  # Replace with actual validation loss\n",
    "    \n",
    "    # Step the scheduler based on the validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Learning rate is {optimizer.param_groups[0]['lr']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52eed1-c0dc-496d-a042-d9d20dc63f46",
   "metadata": {},
   "source": [
    "#### CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcccaf-7099-4d6d-9d0b-e668c6c78513",
   "metadata": {},
   "source": [
    "CosineAnnealingLR adjusts the learning rate following a cosine annealing schedule, which reduces the learning rate from an initial value to close to zero over a fixed number of epochs (T_max). This scheduler is often used in scenarios where the learning rate is gradually decreased in a non-linear fashion, often leading to better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80ae4c-cbfa-4e95-b143-6b207bb6d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example model and optimizer\n",
    "model = nn.Linear(in_features=128, out_features=64)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# CosineAnnealingLR scheduler: Adjusts the learning rate using a cosine annealing schedule\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(50):\n",
    "    # Training code...\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Learning rate is {scheduler.get_last_lr()[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d3096-035a-497e-8c20-26ca4d6b5f7c",
   "metadata": {},
   "source": [
    "### Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d9e76-fccc-4b38-9515-169aafa8791a",
   "metadata": {},
   "source": [
    "#### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cd648-96f5-4100-843d-039ecb7085ee",
   "metadata": {},
   "source": [
    "nn.Sequential is a container that allows you to stack multiple layers or operations in a sequential order. It passes the output of one layer as the input to the next layer. This is useful for building simple feedforward networks where layers are applied one after another without any branching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c005e-8540-4aa6-8735-7e1dcf4f3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Linear(in_features=16 * 32 * 32, out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64, out_features=10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d30fa-dde9-4ea1-9edd-975c1a44c6ce",
   "metadata": {},
   "source": [
    "#### nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602ffcc-d930-4504-a674-7d59e1fa36eb",
   "metadata": {},
   "source": [
    "nn.ModuleList is a container that holds submodules (layers) in a list. Unlike nn.Sequential, nn.ModuleList does not enforce any order or connectivity between the layers. You must explicitly define how the layers are connected in the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be2dfd-260a-4a04-926b-c3d4ba714e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.layers = nn.ModuleList([\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87530f-f9fa-4a11-8efd-b3cf6f917bf3",
   "metadata": {},
   "source": [
    "#### nn.ModuleDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506fe2d-8b45-415e-9657-ae57f30be119",
   "metadata": {},
   "source": [
    "nn.ModuleDict is a container that holds submodules (layers) in a dictionary with named keys. This is useful when you want to have multiple named submodules that you can access and use in different ways within your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03646e2-d088-422c-97ed-3c5fc6008d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.layers = nn.ModuleDict({\n",
    "    'conv1': nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "    'conv2': nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "    'fc1': nn.Linear(32 * 32 * 32, 64),\n",
    "    'fc2': nn.Linear(64, 10)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03acb073-776c-4449-95d2-fa638ee5a638",
   "metadata": {},
   "source": [
    "# torch.nn.functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05a1a7-366a-477c-bb57-28f2bf714217",
   "metadata": {},
   "source": [
    "### Activation Functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2274e-2f8a-4ad5-985c-7840c3d7c344",
   "metadata": {},
   "source": [
    "#### F.relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a5ee8-efc1-485e-85e4-32ea94249a61",
   "metadata": {},
   "source": [
    "ReLU (Rectified Linear Unit) is a widely used activation function in neural networks, especially in convolutional layers. It introduces non-linearity by outputting the input directly if it is positive; otherwise, it outputs zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c885767-ce45-4129-ab03-5d4a5ffc8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example input tensor\n",
    "input_tensor = torch.randn(32, 128)  # Batch of 32, 128 features\n",
    "\n",
    "# Apply ReLU activation function\n",
    "output = F.relu(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a1ccc-da0f-4779-8d9b-420d870924fc",
   "metadata": {},
   "source": [
    "#### F.sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa782712-39dc-4e7b-bb8a-57685dc9ce21",
   "metadata": {},
   "source": [
    "The sigmoid function squashes the input values to the range (0, 1), making it suitable for binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c1b19-8a0e-4bc7-b258-48329120025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sigmoid activation function\n",
    "output = F.sigmoid(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a04d3f-e114-4c46-9647-954829d5b6b0",
   "metadata": {},
   "source": [
    "#### F.tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b75c0-db80-4fd0-91b9-2aec005d98be",
   "metadata": {},
   "source": [
    "The tanh (hyperbolic tangent) function squashes the input values to the range (-1, 1). It is often used in the hidden layers of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef7e13-eb98-4598-b40d-d54c80c71fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Tanh activation function\n",
    "output = F.tanh(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be23fe-cfe2-4764-a959-2b9bb72efafd",
   "metadata": {},
   "source": [
    "#### F.leaky_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1acc8-01c9-43e3-9218-de13f71b8073",
   "metadata": {},
   "source": [
    "Leaky ReLU is a variant of ReLU that allows a small, non-zero gradient when the input is negative, helping to mitigate the \"dying ReLU\" problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f7c31-e8ea-4307-a14d-baaeba2ddb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Leaky ReLU activation function\n",
    "output = F.leaky_relu(input_tensor, negative_slope=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8938c-8120-4ad1-ad6e-1b4b074a9b3f",
   "metadata": {},
   "source": [
    "#### F.elu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4faab-4983-4464-b4e3-2b7d4e6950be",
   "metadata": {},
   "source": [
    "ELU (Exponential Linear Unit) is an advanced activation function that improves learning characteristics by having non-zero outputs for negative inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633f697-b8b1-4f29-8189-725fb20fd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ELU activation function\n",
    "output = F.elu(input_tensor, alpha=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb250c6-e64a-487b-87c2-c882e576ac4a",
   "metadata": {},
   "source": [
    "#### F.selu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27afc2-02ab-4d47-9372-3ae37f060cd3",
   "metadata": {},
   "source": [
    "SELU (Scaled Exponential Linear Unit) is a self-normalizing activation function that automatically normalizes the output of each layer to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6ee5f-fae9-472c-83a3-bab6a6e533e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SELU activation function\n",
    "output = F.selu(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf43757-4e17-436c-9ec7-8e205b5d926f",
   "metadata": {},
   "source": [
    "#### F.softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bcd4d7-5adf-4c99-a8ad-9712c62f426f",
   "metadata": {},
   "source": [
    "Softmax is often used in the final layer of a neural network for multi-class classification. It converts raw logits into probabilities that sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54a2a9-7b6a-495d-bc42-f94035d920db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Softmax activation function\n",
    "output = F.softmax(input_tensor, dim=1)  # Apply along the class dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fe633-3452-4bd3-94a3-c7ee89d391c6",
   "metadata": {},
   "source": [
    "#### F.log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba5ef1-7128-4fac-8415-c924ecf4543c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef81045-8503-4d4a-a70e-6264c266bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation Functions:\n",
    "F.relu, F.sigmoid, F.tanh: Basic activation functions.\n",
    "F.leaky_relu, F.elu, F.selu: Advanced activation functions for specific use cases.\n",
    "F.softmax, F.log_softmax: Functions for output layers in classification tasks.\n",
    ". I want code and explanation like \n",
    "liner:\n",
    "Explanation:\n",
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "output = linear(input_tensor)\n",
    "nn.Conv2d:\n",
    "Explanation:\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "output = conv(input_tensor) Same for each like conv3d,3d or lstm gru like this for each present in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29217c6-103f-48ba-a904-95aa80cd1062",
   "metadata": {},
   "source": [
    "### Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758228d5-5e11-40aa-8ffc-3813a16dafb0",
   "metadata": {},
   "source": [
    "#### F.max_pool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6bee2-1019-4fb1-83d3-d3317b0a386f",
   "metadata": {},
   "source": [
    "F.max_pool2d applies a 2D max pooling over an input signal composed of several input planes. This operation downsamples the input by taking the maximum value in each kernel-sized window.\n",
    "\n",
    "kernel_size=2: The size of the window to take a max over.\n",
    "stride=2: The stride of the window.\n",
    "padding=0: The amount of zero-padding added to both sides of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5d05e-6e11-44da-b647-ee4de7c81bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input tensor of shape (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(1, 16, 32, 32)\n",
    "\n",
    "# Apply 2D max pooling\n",
    "output = F.max_pool2d(input_tensor, kernel_size=2, stride=2, padding=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486c00d-2277-40fc-a64b-3d59dda670be",
   "metadata": {},
   "source": [
    "#### F.avg_pool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a961a-0bdc-40ef-ae3b-24d46d350c0e",
   "metadata": {},
   "source": [
    "F.avg_pool2d applies a 2D average pooling over an input signal composed of several input planes. This operation downsamples the input by taking the average value in each kernel-sized window.\n",
    "\n",
    "kernel_size=2: The size of the window to take an average over.\n",
    "stride=2: The stride of the window.\n",
    "padding=0: The amount of zero-padding added to both sides of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c9b5b-fdf4-43c8-b96c-859d27e65da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input tensor of shape (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(1, 16, 32, 32)\n",
    "\n",
    "# Apply 2D average pooling\n",
    "output = F.avg_pool2d(input_tensor, kernel_size=2, stride=2, padding=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9cc50-dc47-406e-b2ef-14e9c885f711",
   "metadata": {},
   "source": [
    "#### F.max_pool1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16030f5-39c3-483d-8e81-3a915c45d366",
   "metadata": {},
   "source": [
    "F.max_pool1d applies a 1D max pooling over an input signal composed of several input planes. This operation downsamples the input by taking the maximum value in each kernel-sized window\n",
    "\n",
    "kernel_size=2: The size of the window to take a max over.\n",
    "stride=2: The stride of the window.\n",
    "padding=0: The amount of zero-padding added to both sides of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19d8c7-e62b-48f7-83d1-fc3b78e9367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input tensor of shape (batch_size, channels, length)\n",
    "input_tensor = torch.randn(1, 16, 50)\n",
    "\n",
    "# Apply 1D max pooling\n",
    "output = F.max_pool1d(input_tensor, kernel_size=2, stride=2, padding=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde4aca-3271-4c61-bc32-05ea4f5ca625",
   "metadata": {},
   "source": [
    "#### F.avg_pool1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3e6fa-fa63-4f86-8e61-4bea01f4443c",
   "metadata": {},
   "source": [
    "F.avg_pool1d applies a 1D average pooling over an input signal composed of several input planes. This operation downsamples the input by taking the average value in each kernel-sized window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1adad-c235-48de-a81f-d62361a2af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input tensor of shape (batch_size, channels, length)\n",
    "input_tensor = torch.randn(1, 16, 50)\n",
    "\n",
    "# Apply 1D average pooling\n",
    "output = F.avg_pool1d(input_tensor, kernel_size=2, stride=2, padding=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c51bc-2468-41c8-acf8-b12fd03eeaf9",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b833d57-f3c4-4120-8ab9-178f44386342",
   "metadata": {},
   "source": [
    "#### F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13784a5-b633-41e9-8047-34f9b9f87b9e",
   "metadata": {},
   "source": [
    "F.cross_entropy combines a softmax operation and a negative log likelihood loss in one function. It's typically used for multi-class classification problems where the model outputs raw logits (unnormalized scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9274c-51cb-489c-8608-3f63ceed7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming `logits` is the output from the final layer of the model (before softmax) and `labels` is the ground truth.\n",
    "logits = torch.randn(64, 10)  # Example logits for a batch size of 64 and 10 classes\n",
    "labels = torch.randint(0, 10, (64,))  # Example labels for the same batch size\n",
    "\n",
    "# Cross entropy loss combines softmax and NLL loss\n",
    "loss = F.cross_entropy(logits, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67073f-a8af-41bf-a414-0c0e070faec8",
   "metadata": {},
   "source": [
    "#### F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6582c-ee6e-4f02-9be4-a7ce667ca610",
   "metadata": {},
   "source": [
    "F.mse_loss is the functional version of the Mean Squared Error (MSE) loss, which is used for regression tasks. It calculates the average squared difference between the predicted values and the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d15ef0-a86f-4ba3-992f-9a30efdbc0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming `predictions` is the output of the model and `targets` is the ground truth.\n",
    "predictions = torch.randn(64, 1)  # Example predictions for a batch size of 64\n",
    "targets = torch.randn(64, 1)  # Example target values\n",
    "\n",
    "# Mean squared error loss\n",
    "loss = F.mse_loss(predictions, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5b874-a948-4392-9bf9-334c838b3ad8",
   "metadata": {},
   "source": [
    "#### F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a83a9-1959-4ab8-9c17-0d0503552885",
   "metadata": {},
   "source": [
    "F.binary_cross_entropy is the functional version of binary cross-entropy loss. It's typically used for binary classification tasks, where each output is a probability (usually after a sigmoid function) indicating the likelihood of belonging to the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9a7dc-f1fe-493e-93c3-22fe63bfb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming `outputs` are the predicted probabilities after a sigmoid activation and `targets` are the binary labels.\n",
    "outputs = torch.sigmoid(torch.randn(64, 1))  # Example outputs for a batch size of 64\n",
    "targets = torch.randint(0, 2, (64, 1)).float()  # Example binary labels\n",
    "\n",
    "# Binary cross-entropy loss\n",
    "loss = F.binary_cross_entropy(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfe482-5f5e-4335-ad35-ac57338b6fbb",
   "metadata": {},
   "source": [
    "# torch.nn.init "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b22236-e56a-4ea6-9309-6cfa5dcb923f",
   "metadata": {},
   "source": [
    "### Initialization Methods:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5711de-df88-4816-8b0d-5a7624ada758",
   "metadata": {},
   "source": [
    "#### init.xavier_uniform_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5aaf8b-ccc1-49e0-8543-fba9e71c70b1",
   "metadata": {},
   "source": [
    "init.xavier_uniform_ initializes the weights of a layer using a uniform distribution. The range of the distribution is determined by the number of input and output units in the layer. This initialization is well-suited for layers with tanh or sigmoid activation functions as it helps maintain the variance of the activations throughout the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1198fd-6bae-4685-98ad-b9e261c3dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Define a linear layer\n",
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "\n",
    "# Apply Xavier uniform initialization to the weights\n",
    "init.xavier_uniform_(linear.weight)\n",
    "\n",
    "# Forward pass\n",
    "input_tensor = torch.randn(32, 128)  # Batch size of 32\n",
    "output = linear(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81c464-36f6-4b51-afaf-391d61f49433",
   "metadata": {},
   "source": [
    "#### init.xavier_normal_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24006a58-5803-4590-992c-5f4ada4a0eda",
   "metadata": {},
   "source": [
    "init.xavier_normal_ initializes the weights of a layer using a normal distribution with mean 0 and variance determined by the number of input and output units. Like xavier_uniform_, it is best suited for layers with tanh or sigmoid activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfbb17-8814-48d4-ae1f-92c4f7b36e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear layer\n",
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "\n",
    "# Apply Xavier normal initialization to the weights\n",
    "init.xavier_normal_(linear.weight)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07edd9e-c3f0-4cea-b548-7cbd94d376db",
   "metadata": {},
   "source": [
    "#### init.kaiming_uniform_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8c8b1-0d9a-403f-ab41-002105dc8986",
   "metadata": {},
   "source": [
    "init.kaiming_uniform_, also known as He initialization, is designed for layers using ReLU or other activation functions that do not saturate. It initializes the weights using a uniform distribution, scaled according to the number of input units. This helps in maintaining the variance of the activations, preventing issues like vanishing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23599f9a-30e7-4104-a237-f621ca5cc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Conv2d layer\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Apply Kaiming uniform initialization to the weights\n",
    "init.kaiming_uniform_(conv.weight, nonlinearity='relu')\n",
    "\n",
    "# Forward pass\n",
    "input_tensor = torch.randn(32, 3, 64, 64)  # Batch size of 32, 3 channels, 64x64 image\n",
    "output = conv(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbfffe-0e3f-4060-aa46-14dd61a9fffe",
   "metadata": {},
   "source": [
    "#### init.kaiming_normal_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758ff27-d276-4f76-afe8-778b43b6c16e",
   "metadata": {},
   "source": [
    "init.kaiming_normal_ initializes the weights of a layer using a normal distribution. Like kaiming_uniform_, it is tailored for ReLU and similar activation functions. The weights are sampled from a normal distribution scaled based on the number of input units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351d29e-13e9-43d5-8d5f-54042e3495c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Conv2d layer\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Apply Kaiming normal initialization to the weights\n",
    "init.kaiming_normal_(conv.weight, nonlinearity='relu')\n",
    "\n",
    "# Forward pass\n",
    "output = conv(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883815ff-0e41-4087-8abb-cc9bcad0163a",
   "metadata": {},
   "source": [
    "#### init.orthogonal_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52411d-b237-4fa5-8efc-80b5aaa6af54",
   "metadata": {},
   "source": [
    "init.orthogonal_ initializes the weights of a layer with a (semi-)orthogonal matrix. This is particularly useful for RNNs, LSTMs, and GRUs as it helps in preserving gradients over many time steps, making the training of deep RNNs more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f7b20-beed-467f-84d4-ad26f61ac577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an LSTM layer\n",
    "lstm = nn.LSTM(input_size=128, hidden_size=64, num_layers=2)\n",
    "\n",
    "# Apply orthogonal initialization to the weights of the LSTM\n",
    "for name, param in lstm.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.orthogonal_(param)\n",
    "\n",
    "# Forward pass\n",
    "input_tensor = torch.randn(32, 50, 128)  # Batch size of 32, sequence length of 50, input size of 128\n",
    "output, _ = lstm(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc1b17e-8f3e-496f-aaeb-6512c2dfb62f",
   "metadata": {},
   "source": [
    "#### init.zeros_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07497ae-690a-4de5-a770-42271b889c79",
   "metadata": {},
   "source": [
    "init.zeros_ initializes the weights or biases of a layer to zero. This can be useful when you want to start with zero weights or ensure that biases are initially neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409969d-d68d-470b-8829-2bc98dd774d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear layer\n",
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "\n",
    "# Apply zero initialization to the biases\n",
    "init.zeros_(linear.bias)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118076f-6e00-4576-aec1-4e980553a23f",
   "metadata": {},
   "source": [
    "#### init.ones_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339ee27-39c0-4426-ad9e-f25b8b6cb308",
   "metadata": {},
   "source": [
    "init.ones_ initializes the weights or biases of a layer to one. This is less commonly used for weights, but it can be useful for initializing biases in certain architectures where you want to start with a positive bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65662d3-34e7-4bb0-9393-7754254793dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear layer\n",
    "linear = nn.Linear(in_features=128, out_features=64)\n",
    "\n",
    "# Apply one initialization to the biases\n",
    "init.ones_(linear.bias)\n",
    "\n",
    "# Forward pass\n",
    "output = linear(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696f4b2-4c4f-4ad3-a7d8-5123b8ad011f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d25098a-4cba-4baa-b61f-7bd111aa725c",
   "metadata": {},
   "source": [
    "# ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395366ed-83ac-4c27-b0e8-85802cf6bb8c",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e52674-94fc-4b2c-b123-fca6e936b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the regression model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=1):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "        # Weight Initialization\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # ReLU activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)  # No activation function for the output layer\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = RegressionModel()\n",
    "\n",
    "# Load the dataset (using a regression task)\n",
    "url = 'https://your_dataset_url.com'  # Replace with actual regression dataset URL\n",
    "my_df = pd.read_csv(url)\n",
    "\n",
    "# Assume the dataset has a structure suitable for regression\n",
    "# X would be features and y would be a continuous target variable\n",
    "X = my_df.drop('target_column', axis=1).values  # Replace 'target_column' with actual target column name\n",
    "y = my_df['target_column'].values\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "# Convert y labels to float tensors for MSELoss\n",
    "y_train = torch.FloatTensor(y_train).view(-1, 1)  # Reshape to (batch_size, 1)\n",
    "y_test = torch.FloatTensor(y_test).view(-1, 1)    # Reshape to (batch_size, 1)\n",
    "\n",
    "# Loss function: Mean Squared Error (MSE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer: Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train)  # Get predicted results\n",
    "\n",
    "    # Measure the loss/error\n",
    "    loss = criterion(y_pred, y_train)  # predicted values vs the y_train\n",
    "\n",
    "    # Keep Track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Plot the loss over epochs\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate Model on Test Data Set (validate model on test set)\n",
    "with torch.no_grad():  # Turn off backpropagation\n",
    "    y_eval = model(X_test)  # Forward pass\n",
    "    test_loss = criterion(y_eval, y_test)  # Compute test loss\n",
    "    print(f'Test Loss: {test_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e058972-c4cb-4223-8b0f-359f4f8d1386",
   "metadata": {},
   "source": [
    "#### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00b15e-923a-4bd7-b3fd-e8d100754847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the binary classification model\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=8, h2=9):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, 1)  # 1 output neuron for binary classification\n",
    "\n",
    "        # Weight Initialization\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # ReLU activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.out(x))  # Sigmoid activation function for binary classification\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = BinaryClassificationModel()\n",
    "\n",
    "# Load the dataset (similar to previous example)\n",
    "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "my_df = pd.read_csv(url)\n",
    "\n",
    "# Binary classification: Let's classify 'Setosa' (0) vs. 'Not Setosa' (1)\n",
    "my_df['binary_variety'] = my_df['variety'].apply(lambda x: 1.0 if x != 'Setosa' else 0.0)\n",
    "\n",
    "# Train Test Split! Set X, y\n",
    "X = my_df.drop(['variety', 'binary_variety'], axis=1).values\n",
    "y = my_df['binary_variety'].values\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "# Convert y labels to float tensors for BCEWithLogitsLoss\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "# Loss function: Binary Cross Entropy with Logits\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer: Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train)  # Get predicted results\n",
    "\n",
    "    # Measure the loss/error\n",
    "    loss = criterion(y_pred, y_train)  # predicted values vs the y_train\n",
    "\n",
    "    # Keep Track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Plot the loss over epochs\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate Model on Test Data Set (validate model on test set)\n",
    "with torch.no_grad():  # Turn off backpropagation\n",
    "    y_eval = model(X_test).squeeze()  # Forward pass\n",
    "    test_loss = criterion(y_eval, y_test)  # Compute test loss\n",
    "    print(f'Test Loss: {test_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43135856-9bf7-4c0c-b66d-3f3a5f83f684",
   "metadata": {},
   "source": [
    "#### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74facb32-2717-43dc-aa9e-1690f70f8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the classification model\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):  # 3 output classes for Iris\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "        # Weight Initialization\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # ReLU activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)  # No activation function; CrossEntropyLoss will apply softmax\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = ClassificationModel()\n",
    "\n",
    "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "my_df = pd.read_csv(url)\n",
    "\n",
    "# Change last column from strings to integers\n",
    "my_df['variety'] = my_df['variety'].replace({'Setosa': 0.0, 'Versicolor': 1.0, 'Virginica': 2.0})\n",
    "\n",
    "# Train Test Split! Set X, y\n",
    "X = my_df.drop('variety', axis=1).values\n",
    "y = my_df['variety'].values\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "# Convert y labels to tensors long (required for CrossEntropyLoss)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# Loss function: CrossEntropyLoss for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train)  # Get predicted results\n",
    "\n",
    "    # Measure the loss/error, gonna be high at first\n",
    "    loss = criterion(y_pred, y_train)  # predicted values vs the y_train\n",
    "\n",
    "    # Keep Track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # print every 10 epochs\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Graph it out!\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate Model on Test Data Set (validate model on test set)\n",
    "with torch.no_grad():  # Turn off backpropagation\n",
    "    y_eval = model.forward(X_test)  # X_test are features from our test set, y_eval will be predictions\n",
    "    loss = criterion(y_eval, y_test)  # Find the loss or error\n",
    "    print(f'Test Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f004f-92c1-4fd7-aa37-4ae580dff30c",
   "metadata": {},
   "source": [
    "##### The choice of weight initialization techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43bf3f4-891b-4c6f-92c9-08b00303866d",
   "metadata": {},
   "source": [
    "1. Use Kaiming Initialization for ReLU Activation Layers\n",
    "Kaiming Initialization is used for layers with ReLU activation functions because it maintains the variance of the activations, preventing the issue of dying ReLUs.\n",
    "2. Use Xavier Initialization for Sigmoid, Tanh, or Linear Activation Layers\n",
    "Xavier Initialization is used for the output layer where the activation function is either sigmoid (in the binary case) or none (in the multi-class case, where CrossEntropyLoss handles the softmax internally). This choice ensures that the weights are scaled appropriately, facilitating effective learning from the outset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80007d-f85e-479d-8561-756793812a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaiming Initialization\n",
    "nn.init.kaiming_uniform_(self.fcX.weight, nonlinearity='relu')\n",
    "\n",
    "# Xavier Initialization\n",
    "nn.init.xavier_uniform_(self.fcX.weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23dc69f-7c17-4055-a8ed-6f4210745fb6",
   "metadata": {},
   "source": [
    "#### Handle multiple hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f3726-b884-4fac-b888-ba67044de959",
   "metadata": {},
   "source": [
    "1. Deeper Networks: As the network depth increases, the choice of activation functions and initialization methods becomes even more critical. Proper initialization can prevent issues like vanishing/exploding gradients, which are more prevalent in deeper networks.\n",
    "\n",
    "2. Batch Normalization: For very deep networks, you might also consider using batch normalization (nn.BatchNorm1d, nn.BatchNorm2d) to further stabilize the training process and allow for higher learning rates.\n",
    "\n",
    "3. Dropout: To prevent overfitting, especially in deeper networks, you can also incorporate dropout layers between hidden layers.\n",
    "   self.dropout = nn.Dropout(p=0.5)  # 50% dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2dd0af-e773-4b2b-814e-fae22cb49f5e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa93643-c5b9-4431-bd37-77231fb29f56",
   "metadata": {},
   "source": [
    "#### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2e4d7-5866-4277-83cb-b97e303a8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2063ef-4b56-40c7-bbb9-c47fcbf4dc80",
   "metadata": {},
   "source": [
    "#### 2. Define Image Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd050b-86ee-4379-9436-ade44c47e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a281eb2-a4ba-496a-8429-378732aae574",
   "metadata": {},
   "source": [
    "#### 3. Load Custom Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c68d65-eea0-4042-8c18-0523140f4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your custom image\n",
    "custom_image_path = r'C:\\Users\\DK\\Desktop\\DKTech\\pytorch\\cnn\\input'\n",
    "\n",
    "# Load the custom dataset\n",
    "dataset = ImageFolder(root=custom_image_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a5f2f-8a84-4d78-a7ba-63b87c452e14",
   "metadata": {},
   "source": [
    "#### 4. Split Dataset into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf26bae-5478-4fe5-9b3d-244f28e6faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets (80-20 split)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6e9e4-ef96-4705-baf5-e2737c8d5b4b",
   "metadata": {},
   "source": [
    "#### 5. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f1d35-5d8b-4135-87ee-69c0adb1ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef7ddd-0b6c-4a26-ae10-0ee38fca720d",
   "metadata": {},
   "source": [
    "#### 6. Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4d6e6-84ae-4b24-b60e-492156b91108",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 2)  # 2 output classes: baby and flower\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "### Important #### \n",
    "#****** How to finds 32 * 56 * 56 of self.fc1 = nn.Linear(32 * 56 * 56, 64)? **************\n",
    "\"\"\"\n",
    "formula for conv2d:\n",
    "OutputDimension for conv layer= (InputDimensionKernelSize+2Padding)/Stride} +1\n",
    "first conv2d    = {(224 - 3 + 2 * 1)/1}+1 = 224 = 16*224*224\n",
    "OutputDimension pooling layer= {(InputDimension of conv  KernelSize)/Stride}+1\n",
    "first pooling = {(224 - 2)/2} +1 = 112 = 16*112*112  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105771a-2ea3-4c87-93dd-1f705d3adfd7",
   "metadata": {},
   "source": [
    "#### 7. Instantiate the Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89b5a4-2376-4cb5-9987-9aa53e8d2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)# Smaller the Learning Rate, longer its gonna take to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225dd3e3-c5ec-4267-8105-10fd2d5f07fa",
   "metadata": {},
   "source": [
    "#### 8. Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f32f5-074e-4f0a-a7ce-bc8a9f23d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_correct = []\n",
    "val_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    # Training Loop\n",
    "    model.train()\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b += 1\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if b % 600 == 0:\n",
    "            print(f'Epoch: {i+1}  Batch: {b}  Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "    train_correct.append(trn_corr.item())\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for b, (X_val, y_val) in enumerate(val_loader):\n",
    "            y_val = model(X_val)\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_val).sum()\n",
    "\n",
    "    val_losses.append(criterion(y_val, y_val).item())\n",
    "    val_correct.append(tst_corr.item())\n",
    "\n",
    "    print(f'Epoch {i+1} completed. Training Loss: {train_losses[-1]:.4f}, '\n",
    "          f'Training Accuracy: {train_correct[-1] / len(train_dataset) * 100:.2f}%, '\n",
    "          f'Validation Loss: {val_losses[-1]:.4f}, '\n",
    "          f'Validation Accuracy: {val_correct[-1] / len(val_dataset) * 100:.2f}%')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'Training Took: {total_time / 60:.2f} minutes!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501cdb4-1647-40ef-be02-c117c065fc7f",
   "metadata": {},
   "source": [
    "#### 9. Visualize Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead32145-65b2-481f-8efb-27c486f56aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss at Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a53cc-bc14-4521-943b-7dd9fb3995e5",
   "metadata": {},
   "source": [
    "#### 10. Visualize Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585706b-85c5-4f44-abab-e904b9bed799",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([t / len(train_dataset) * 100 for t in train_correct], label=\"Training Accuracy\")\n",
    "plt.plot([t / len(val_dataset) * 100 for t in val_correct], label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy at the end of each Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e54e71-b7d6-4928-9105-a656b208af54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52d4fb-7195-4a73-bdee-e586a7aed779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fa062-71c9-4812-a295-02b91e002403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109f45a-64d6-44d5-ac7f-74b54ea7b7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
