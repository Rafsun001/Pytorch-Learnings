{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9819fd4b",
   "metadata": {},
   "source": [
    "#### Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#From Data: Creating a tensor from a list\n",
    "t1 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32, device='cpu', requires_grad=True)\n",
    "# dtype: Controls numeric type (float32 for training), device: where to store (CPU/GPU), requires_grad: track for backprop\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "#From NumPy Arrays\n",
    "np_array = np.array([[1, 2], [3, 4]])\n",
    "x = torch.from_numpy(np_array)\n",
    "\n",
    "# Using tensor\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "# Zeros tensor with all common attributes\n",
    "zeros = torch.zeros(3, 3, dtype=torch.float32, device='cuda:0', requires_grad=True)\n",
    "\n",
    "# Ones tensor with int type on CPU (e.g. binary mask)\n",
    "ones = torch.ones(2, 2,dtype=torch.int32,device='cpu', requires_grad=False)\n",
    "\n",
    "# Tensor random values\n",
    "rand = torch.rand(4, 4)\n",
    "\n",
    "# Tensor random values\n",
    "torch.manual_seed(132)\n",
    "rand = torch.rand(4, 4)\n",
    "\n",
    "\n",
    "# torch.empty_like(x)\n",
    "# ➤ Creates an uninitialized tensor with same shape, dtype, and device as x\n",
    "# Use Case: Allocate space quickly (e.g. for output buffers), to be filled later\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cpu',requires_grad=True)\n",
    "empty_like_x = torch.empty_like(x)\n",
    "\n",
    "# torch.zeros_like(x)\n",
    "# ➤ Creates a tensor of all zeros with the same shape, dtype, device as x\n",
    "# Use Case: Create padding masks, bias placeholders, zero accumulators\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cuda:0',requires_grad=True)\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "\n",
    "\n",
    "# torch.ones_like(x)\n",
    "# ➤ Creates a tensor of all ones with same shape, dtype, device as x\n",
    "# Use Case: Multiplicative identity masks, debug constants\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cpu',requires_grad=True)\n",
    "ones_like_x = torch.ones_like(x)\n",
    "\n",
    "# torch.rand_like(x, dtype=torch.float32)\n",
    "# ➤ Creates random values with same shape as x, override dtype to float\n",
    "# Use Case: Random input generation for same-shaped tensors (e.g. noise, synthetic features)\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cuda:0',requires_grad=True)\n",
    "rand_like_x = torch.rand_like(x, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Diagonal matrix\n",
    "# Square matrix with non-zero elements only on the main diagonal\n",
    "# Use case: Scaling vectors or representing covariance diagonal\n",
    "diag_elements = torch.tensor([1, 2, 3, 4])\n",
    "diag_matrix = torch.diag(diag_elements)\n",
    "print(\"Diagonal matrix:\\n\", diag_matrix)\n",
    "\n",
    "# 3. Identity matrix\n",
    "# Square matrix with ones on diagonal and zeros elsewhere\n",
    "# Use case: Multiplicative identity in matrix operations\n",
    "identity = torch.eye(4)\n",
    "print(\"\\nIdentity matrix:\\n\", identity)\n",
    "\n",
    "# 4. Triangular matrix\n",
    "# Upper or lower triangular matrix with zeros below or above diagonal\n",
    "# Use case: Solving linear systems, decompositions\n",
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "upper_tri = torch.triu(A)\n",
    "lower_tri = torch.tril(A)\n",
    "print(\"\\nUpper triangular matrix:\\n\", upper_tri)\n",
    "print(\"\\nLower triangular matrix:\\n\", lower_tri)\n",
    "\n",
    "\n",
    "# 5. Scalar matrix\n",
    "# Scalar multiple of the identity matrix (same scalar on diagonal)\n",
    "# Use case: Scaling operations in transformations\n",
    "scalar = 5\n",
    "scalar_matrix = scalar * torch.eye(3)\n",
    "print(\"\\nScalar matrix:\\n\", scalar_matrix)\n",
    "\n",
    "\n",
    "# 1. torch.empty_like(x)\n",
    "# Creates a new tensor with the same shape, dtype, and device as x\n",
    "# but contents are uninitialized (random memory values).\n",
    "# Use case: Allocate memory quickly for temporary buffers that you will overwrite\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cpu')\n",
    "empty_like_x = torch.empty_like(x)\n",
    "\n",
    "\n",
    "# 2. torch.zeros_like(x)\n",
    "# Creates a new tensor full of zeros, matching x's shape, dtype, and device\n",
    "# Use case: Initialize bias terms, zero masks, or accumulators matching input tensor\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cpu')\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "\n",
    "\n",
    "# 3. torch.ones_like(x)\n",
    "# Creates a tensor full of ones, same shape/dtype/device as x\n",
    "# Use case: Multiplicative identity masks or debug tensors\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cpu')\n",
    "ones_like_x = torch.ones_like(x)\n",
    "\n",
    "\n",
    "# 4. torch.rand_like(x, dtype=torch.float32)\n",
    "# Creates a tensor with random values sampled uniformly from [0,1),\n",
    "# with the same shape as x, but overriding dtype to float32\n",
    "# Use case: Create noise or random initialization matching a reference tensor’s shape\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.int64, device='cpu')\n",
    "rand_like_x = torch.rand_like(x, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62876beb",
   "metadata": {},
   "source": [
    "##### Data Types \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create tensors with different data types\n",
    "tensor_int = torch.tensor([1, 2, 3, 4], dtype=torch.int32)  # 32-bit integers\n",
    "tensor_float = torch.tensor([1.5, 2.5, 3.5, 4.5], dtype=torch.float32)  # 32-bit floating point\n",
    "\n",
    "# 1. Convert tensor from int32 to float32\n",
    "tensor_float_converted = tensor_int.to(torch.float32)\n",
    "\n",
    "# 2. Convert tensor from float32 to int32 (loses precision)\n",
    "tensor_int_converted = tensor_float.to(torch.int32)\n",
    "\n",
    "# 3. Converting tensor to torch.double (64-bit float)\n",
    "tensor_double = tensor_float.to(torch.float64)\n",
    "\n",
    "# 4. Converting a tensor to boolean type (masking example)\n",
    "tensor_bool = tensor_int.to(torch.bool)\n",
    "\n",
    "# 5. Converting tensor to torch.uint8 (typically used for image data)\n",
    "tensor_uint8 = tensor_int.to(torch.uint8)\n",
    "\n",
    "# 6. Using .type() method for data type conversion\n",
    "tensor_type_example = tensor_float.type(torch.int64)\n",
    "\n",
    "# Example of creating a tensor directly with a specific dtype\n",
    "tensor_direct = torch.tensor([1.5, 2.5, 3.5], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6c6c0",
   "metadata": {},
   "source": [
    "#####  Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f76462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Example tensor on CPU\n",
    "tensor_cpu = torch.randn(3, 3)  # A 3x3 random tensor\n",
    "print(\"Tensor on CPU:\")\n",
    "print(tensor_cpu)\n",
    "\n",
    "# Move the tensor to GPU (if available)\n",
    "tensor_gpu = tensor_cpu.to(device)\n",
    "print(\"\\nTensor on GPU (if available):\")\n",
    "print(tensor_gpu)\n",
    "\n",
    "# Define a simple model\n",
    "model = torch.nn.Linear(3, 3)\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Example of performing a forward pass with the model on the selected device\n",
    "input_data = torch.randn(3, 3).to(device)  # Sample input data\n",
    "output = model(input_data)  # Forward pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66fa00",
   "metadata": {},
   "source": [
    "##### Shape & Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# -------------------------------------------\n",
    "# Tensor Reshaping and Manipulation\n",
    "# -------------------------------------------\n",
    "\n",
    "# 1. view(): Reshapes the tensor without changing its underlying data.\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y_view = x.view(3, 2)  # Reshapes to 3x2\n",
    "\n",
    "\n",
    "# 2. reshape(): Similar to view(), but more flexible as it can handle non-contiguous tensors.\n",
    "y_reshape = x.reshape(3, 2)  # Reshapes to 3x2\n",
    "\n",
    "# 3. squeeze(): Removes dimensions of size 1.\n",
    "x_squeeze_input = torch.tensor([[[1], [2], [3]]])  # Shape: (1,3,1)\n",
    "y_squeeze = x_squeeze_input.squeeze()  # Removes single-dimensional entries\n",
    "\n",
    "\n",
    "# 4. unsqueeze(): Adds a dimension of size 1 at the specified position.\n",
    "x_unsqueeze_input = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
    "y_unsqueeze = x_unsqueeze_input.unsqueeze(0)  # Adds a new dimension at position 0\n",
    "\n",
    "\n",
    "# 5. transpose(): Swaps two dimensions in a tensor (useful for matrix operations).\n",
    "x_transpose_input = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y_transpose = x_transpose_input.transpose(0, 1)  # Swaps rows and columns\n",
    "\n",
    "\n",
    "# 6. flatten(): Flattens the tensor into a 1D tensor.\n",
    "x_flatten_input = torch.tensor([[1, 2], [3, 4]])\n",
    "y_flatten = x_flatten_input.flatten()  # Flattens to a 1D tensor\n",
    "\n",
    "# 7. Permute :function in PyTorch is used to change the order of dimensions of a tensor. It doesn't change the actual data of the tensor but rather reorders the dimensions.\n",
    "\n",
    "# Create a 3D tensor with shape (2, 3, 4)\n",
    "# This means it has 2 matrices, each of size 3x4\n",
    "tensor_3d = torch.rand(2, 3, 4)\n",
    "\n",
    "print(\"Original Tensor Shape:\", tensor_3d.shape)\n",
    "\n",
    "# Permute the dimensions of the tensor\n",
    "# In this case, we want to change the order of dimensions\n",
    "# We will move the 1st dimension (2) to the 2nd place, \n",
    "# the 2nd dimension (3) to the 3rd place, and the 3rd dimension (4) to the 1st place.\n",
    "# The new order will be (4, 2, 3) where:\n",
    "# - 4 is the new 1st dimension (originally 3rd)\n",
    "# - 2 is the new 2nd dimension (originally 1st)\n",
    "# - 3 is the new 3rd dimension (originally 2nd)\n",
    "permuted_tensor_3d = tensor_3d.permute(2, 0, 1)\n",
    "\n",
    "print(\"Permuted Tensor Shape:\", permuted_tensor_3d.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53e569",
   "metadata": {},
   "source": [
    "#### Indexing & Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# -------------------------------------------\n",
    "# Indexing and Slicing in PyTorch\n",
    "# -------------------------------------------\n",
    "\n",
    "# Creating a 3x3 tensor\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6], \n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# 1. Selecting a specific element from the tensor\n",
    "element = x[1, 2]  # Selects the element at row index 1 and column index 2 (zero-based indexing)\n",
    "print(\"Selected Element:\", element)  # Output: tensor(6)\n",
    "\n",
    "# 2. Selecting an entire row\n",
    "row = x[0, :]  # Selects all elements in row index 0\n",
    "print(\"Selected Row:\", row)  # Output: tensor([1, 2, 3])\n",
    "\n",
    "# 3. Selecting an entire column\n",
    "column = x[:, 1]  # Selects all elements in column index 1\n",
    "print(\"Selected Column:\", column)  # Output: tensor([2, 5, 8])\n",
    "\n",
    "# 4. Selecting a sub-tensor (slicing)\n",
    "# Extracts rows from index 0 to 1 (exclusive of 2) and columns from index 1 to 2 (exclusive of 3)\n",
    "sub_tensor = x[0:2, 1:3]  \n",
    "print(\"Sliced Sub-Tensor:\\n\", sub_tensor)  \n",
    "# Output:\n",
    "# tensor([[2, 3],\n",
    "#         [5, 6]])\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Boolean Indexing in PyTorch\n",
    "# -------------------------------------------\n",
    "\n",
    "# Creating a 1D tensor\n",
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 5. Boolean indexing: Selecting values greater than 3\n",
    "mask = x > 3  # Creates a boolean mask (True for values greater than 3)\n",
    "filtered = x[mask]  # Uses the mask to filter elements\n",
    "print(\"Filtered Elements (x > 3):\", filtered)  # Output: tensor([4, 5])\n",
    "\n",
    "# The boolean mask looks like: tensor([False, False, False, True, True])\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Fancy Indexing in PyTorch\n",
    "# -------------------------------------------\n",
    "\n",
    "# Creating another 1D tensor\n",
    "x = torch.tensor([10, 20, 30, 40, 50])\n",
    "\n",
    "# 6. Fancy indexing using a tensor of indices\n",
    "indices = torch.tensor([0, 3, 4])  # Selecting elements at index positions 0, 3, and 4\n",
    "selected = x[indices]  # Retrieves elements at those positions\n",
    "print(\"Selected Elements via Fancy Indexing:\", selected)  \n",
    "# Output: tensor([10, 40, 50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b5e1c",
   "metadata": {},
   "source": [
    "##### Concatenation & Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. stack(): Stacks multiple tensors along a new dimension.\n",
    "x1 = torch.tensor([1, 2])\n",
    "x2 = torch.tensor([3, 4])\n",
    "y_stack = torch.stack((x1, x2), dim=0)  # Stacks along a new dimension\n",
    "\n",
    "# 8. cat(): Concatenates tensors along a given dimension.\n",
    "\n",
    "# Example: Concatenating along rows (dim=0)\n",
    "x1_cat = torch.tensor([[1, 2], [3, 4]])\n",
    "x2_cat = torch.tensor([[5, 6], [7, 8]])\n",
    "y_cat_rows = torch.cat((x1_cat, x2_cat), dim=0)  # Adds more rows\n",
    "\n",
    "\n",
    "# Example: Concatenating along columns (dim=1)\n",
    "y_cat_cols = torch.cat((x1_cat, x2_cat), dim=1)  # Adds more columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cf4a8",
   "metadata": {},
   "source": [
    "##### Mathmatical Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Basic Arithmetic Operations\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Creating two 1D tensors\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# Element-wise operations (default behavior in PyTorch)\n",
    "addition = x + y  # Element-wise addition\n",
    "multiplication = x * y  # Element-wise multiplication\n",
    "division = x / y  # Element-wise division\n",
    "\n",
    "# Equivalent alternative using tensor methods\n",
    "result_add = x.add(y)  # Addition\n",
    "result_sub = x.sub(y)  # Subtraction\n",
    "result_mul = x.mul(y)  # Multiplication\n",
    "result_div = x.div(y)  # Division\n",
    "\n",
    "# Integer division (dividing after multiplying by 100 and flooring the result)\n",
    "int_div = (x * 100) // 3\n",
    "\n",
    "# Modulo operation (remainder after integer division)\n",
    "mod_result = ((x * 100) // 3) % 2\n",
    "\n",
    "# Exponentiation (raising to power)\n",
    "power_result = x ** 2\n",
    "\n",
    "# Print results to verify\n",
    "print(\"Addition:\", addition)\n",
    "print(\"Multiplication:\", multiplication)\n",
    "print(\"Division:\", division)\n",
    "print(\"Integer Division:\", int_div)\n",
    "print(\"Modulo:\", mod_result)\n",
    "print(\"Power:\", power_result)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Absolute and Negative Value Operations\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "c = torch.tensor([1, -2, 3, -4])\n",
    "\n",
    "# Absolute values (converts all values to positive)\n",
    "abs_values = torch.abs(c)\n",
    "\n",
    "# Negating values (flipping signs)\n",
    "neg_values = torch.neg(c)\n",
    "\n",
    "print(\"Absolute Values:\", abs_values)\n",
    "print(\"Negated Values:\", neg_values)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Rounding and Clamping Operations\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "d = torch.tensor([1.9, 2.3, 3.7, 4.4])\n",
    "\n",
    "# Rounding to the nearest integer\n",
    "rounded = torch.round(d)\n",
    "\n",
    "# Ceiling (rounding up)\n",
    "ceiled = torch.ceil(d)\n",
    "\n",
    "# Floor (rounding down)\n",
    "floored = torch.floor(d)\n",
    "\n",
    "# Clamping values within a range (values < 2 become 2, values > 3 become 3)\n",
    "clamped = torch.clamp(d, min=2, max=3)\n",
    "\n",
    "print(\"Rounded Values:\", rounded)\n",
    "print(\"Ceil Values:\", ceiled)\n",
    "print(\"Floor Values:\", floored)\n",
    "print(\"Clamped Values:\", clamped)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Mathematical Functions\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "k = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Logarithm (natural log, base e)\n",
    "log_result = torch.log(k)\n",
    "\n",
    "# Exponential (e^x)\n",
    "exp_result = torch.exp(k)\n",
    "\n",
    "# Square root\n",
    "sqrt_result = torch.sqrt(k)\n",
    "\n",
    "# Sigmoid function (used in neural networks)\n",
    "sigmoid_result = torch.sigmoid(k)\n",
    "\n",
    "# Softmax function (used for probability distributions, summing to 1)\n",
    "softmax_result = torch.softmax(k, dim=0)\n",
    "\n",
    "# ReLU (Rectified Linear Unit, used in deep learning to remove negative values)\n",
    "relu_result = torch.relu(k)\n",
    "\n",
    "print(\"Log:\", log_result)\n",
    "print(\"Exp:\", exp_result)\n",
    "print(\"Sqrt:\", sqrt_result)\n",
    "print(\"Sigmoid:\", sigmoid_result)\n",
    "print(\"Softmax:\", softmax_result)\n",
    "print(\"ReLU:\", relu_result)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Reduction Operations (Sum, Mean, Min, Max, etc.)\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Sum of all elements\n",
    "sum_all = x.sum()\n",
    "\n",
    "# Sum along columns (axis 0 → collapses rows)\n",
    "sum_col = torch.sum(x, dim=0)\n",
    "\n",
    "# Sum along rows (axis 1 → collapses columns)\n",
    "sum_row = torch.sum(x, dim=1)\n",
    "\n",
    "# Mean (average) of all elements\n",
    "mean_all = x.mean()\n",
    "\n",
    "# Mean along columns\n",
    "mean_col = torch.mean(x, dim=0)\n",
    "\n",
    "e = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Median (middle value)\n",
    "median_val = torch.median(e)\n",
    "\n",
    "# Maximum and Minimum Values\n",
    "max_val = torch.max(e)\n",
    "min_val = torch.min(e)\n",
    "\n",
    "# Product of all elements\n",
    "product = torch.prod(e)\n",
    "\n",
    "# Standard deviation (spread of values)\n",
    "std_dev = torch.std(e.float())  # Ensure float for precision\n",
    "\n",
    "# Variance (square of standard deviation)\n",
    "variance = torch.var(e.float())\n",
    "\n",
    "# Maximum and Minimum Value Indexes\n",
    "max_index = x.argmax()  # Index of the max value (flattened tensor)\n",
    "min_index = x.argmin()  # Index of the min value (flattened tensor)\n",
    "\n",
    "print(\"Sum:\", sum_all)\n",
    "print(\"Sum along Columns:\", sum_col)\n",
    "print(\"Sum along Rows:\", sum_row)\n",
    "print(\"Mean:\", mean_all)\n",
    "print(\"Mean along Columns:\", mean_col)\n",
    "print(\"Median:\", median_val)\n",
    "print(\"Max:\", max_val)\n",
    "print(\"Min:\", min_val)\n",
    "print(\"Product:\", product)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Max Index:\", max_index)\n",
    "print(\"Min Index:\", min_index)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Matrix Multiplication\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Matrix multiplication using @ operator\n",
    "matrix_mult1 = a @ b\n",
    "\n",
    "# Matrix multiplication using torch.matmul\n",
    "matrix_mult2 = torch.matmul(a, b)\n",
    "\n",
    "print(\"Matrix Multiplication (using @ operator):\\n\", matrix_mult1)\n",
    "print(\"Matrix Multiplication (using torch.matmul):\\n\", matrix_mult2)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# In-Place Operations (Modify Tensor Directly)\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# In-place addition (modifies x directly)\n",
    "x.add_(1.0)\n",
    "\n",
    "print(\"In-place Addition (x + 1):\", x)\n",
    "\n",
    "# Note:\n",
    "# - In-place operations modify the original tensor instead of creating a new one.\n",
    "# - They are denoted by an underscore (_), such as `add_`, `sub_`, `mul_`, etc.\n",
    "# - Using in-place operations can be risky in deep learning since it affects computation graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9787d1b",
   "metadata": {},
   "source": [
    "##### Matrix Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ffb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# -------------------------------------------\n",
    "# Matrix Operations in PyTorch\n",
    "# -------------------------------------------\n",
    "\n",
    "# 1. Creating random integer matrices for demonstration\n",
    "f = torch.randint(size=(2, 3), low=0, high=10)  # 2x3 matrix with random values from 0 to 9\n",
    "g = torch.randint(size=(3, 2), low=0, high=10)  # 3x2 matrix with random values from 0 to 9\n",
    "\n",
    "# 2. Matrix multiplication (Dot product of matrices)\n",
    "# Uses the mathematical operation: result[i][j] = sum(A[i, k] * B[k, j])\n",
    "matrix_product = torch.matmul(f, g)  # Produces a (2x2) matrix\n",
    "\n",
    "# -------------------------------------------\n",
    "# Vector Operations in PyTorch\n",
    "# -------------------------------------------\n",
    "\n",
    "# 3. Defining two 1D vectors for dot product\n",
    "vector1 = torch.tensor([1, 2])  # Vector with 2 elements\n",
    "vector2 = torch.tensor([3, 4])  # Another vector with 2 elements\n",
    "\n",
    "# 4. Computing the dot product (scalar product) of two vectors\n",
    "# Formula: a·b = (1*3) + (2*4) = 3 + 8 = 11\n",
    "dot_product = torch.dot(vector1, vector2)  # Returns a scalar (single value)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Transposition of a Matrix\n",
    "# -------------------------------------------\n",
    "\n",
    "# 5. Transposing matrix `f` (swaps rows and columns)\n",
    "# torch.transpose(f, 0, 1) swaps dimension 0 (rows) with dimension 1 (columns)\n",
    "transposed_f = torch.transpose(f, 0, 1)  # Results in a (3x2) matrix\n",
    "\n",
    "# -------------------------------------------\n",
    "# Determinant and Inverse of a Square Matrix\n",
    "# -------------------------------------------\n",
    "\n",
    "# 6. Creating a square matrix (3x3) with random values for determinant and inverse\n",
    "h = torch.randint(size=(3, 3), low=0, high=10, dtype=torch.float32)  # Random 3x3 matrix\n",
    "\n",
    "# 7. Calculating the determinant of matrix `h`\n",
    "# The determinant is a scalar value that represents how the matrix scales space\n",
    "det_h = torch.det(h)  # Returns a single scalar value\n",
    "print(\"Determinant of h:\", det_h.item())\n",
    "\n",
    "# 8. Computing the inverse of matrix `h`\n",
    "# Only possible if `h` is non-singular (determinant ≠ 0)\n",
    "# If the matrix is singular, this will raise an error\n",
    "if torch.det(h) != 0:  \n",
    "    inverse_h = torch.inverse(h)  # Computes the inverse of `h`\n",
    "else:\n",
    "    inverse_h = \"Matrix is singular, inverse does not exist.\"\n",
    "print(\"Inverse of h:\\n\", inverse_h if isinstance(inverse_h, str) else inverse_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6a798",
   "metadata": {},
   "source": [
    "#### Chunk and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ef769",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Split into 3 chunks\n",
    "chunks = torch.chunk(x, 3)\n",
    "print(chunks)\n",
    "\n",
    "# Split into parts of size 2\n",
    "splits = torch.split(x, 2)\n",
    "print(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb44e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Early stoping\n",
    "2. state save or save model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
