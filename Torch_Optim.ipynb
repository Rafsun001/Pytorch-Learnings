{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "################################################\n",
    "####################   SGD #####################\n",
    "################################################\n",
    "\n",
    "model = torch.nn.Linear(10, 1)  # Simple linear model\n",
    "\n",
    "# SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,           # Learning rate: Controls the step size during updates\n",
    "                      momentum=0.9,      # Momentum: Helps the model move faster in the right direction\n",
    "                      weight_decay=0.01) # Weight decay: L2 regularization to prevent overfitting\n",
    "\n",
    "################################################\n",
    "####################  Adam #####################\n",
    "################################################\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001,          # Learning rate: Controls the step size\n",
    "                       betas=(0.9, 0.999), # betas: Momentum terms for the first and second moment estimates\n",
    "                       eps=1e-08,         # eps: A small value to prevent division by zero during updates\n",
    "                       weight_decay=0.01) # Weight decay: L2 regularization to prevent overfitting\n",
    "\n",
    "################################################\n",
    "################### RMSprop ####################\n",
    "################################################\n",
    "# RMSprop optimizer\n",
    "optimizer = optim.RMSprop(model.parameters(), \n",
    "                          lr=0.01,           # Learning rate: Controls the step size\n",
    "                          alpha=0.99,        # alpha: The smoothing constant, for the moving average of squared gradients\n",
    "                          eps=1e-08,         # eps: Prevents division by zero\n",
    "                          weight_decay=0.01) # Weight decay: L2 regularization\n",
    "\n",
    "################################################\n",
    "################### Adagrad ####################\n",
    "################################################\n",
    "# Adagrad optimizer\n",
    "optimizer = optim.Adagrad(model.parameters(), \n",
    "                          lr=0.01,           # Learning rate\n",
    "                          weight_decay=0.01,  # Weight decay\n",
    "                          initial_accumulator_value=0.1)  # Initializes the accumulator for squared gradients\n",
    "\n",
    "################################################\n",
    "################### AdamW ####################\n",
    "################################################\n",
    "# AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                        lr=0.001,          # Learning rate\n",
    "                        betas=(0.9, 0.999), # Betas for first and second moment estimates\n",
    "                        eps=1e-08,         # Prevents division by zero\n",
    "                        weight_decay=0.01) # Weight decay applied in a more decoupled manner\n",
    "\n",
    "################################################\n",
    "################### Adadelta ###################\n",
    "################################################\n",
    "# Adadelta optimizer\n",
    "optimizer = optim.Adadelta(model.parameters(), \n",
    "                           lr=1.0,            # Learning rate\n",
    "                           rho=0.95,          # Smoothing constant for running average of squared gradients\n",
    "                           eps=1e-06,         # Prevents division by zero\n",
    "                           weight_decay=0.01) # Weight decay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Learning Rate Scheduling Works\n",
    "Learning rate scheduling in deep learning is a technique used to adjust the learning rate during training. The idea is to gradually change the learning rate to help the model converge more efficiently and avoid overfitting or underfitting.\n",
    "\n",
    "During training, the learning rate controls how much to adjust the model's parameters (weights) after each update step. A well-chosen learning rate can make training faster and more stable. However, using a constant learning rate throughout training is often suboptimal. Instead, learning rate schedules adjust the learning rate at different points in the training process to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "################################################\n",
    "################### StepLR #####################\n",
    "################################################\n",
    "\n",
    "\"\"\"\n",
    "The learning rate is reduced by a factor (gamma) after a fixed number of epochs (step_size). This is one of the most commonly used schedules, as it gradually decreases the learning rate over time to allow for finer adjustments as training progresses.\n",
    "\n",
    "Example: Reduce learning rate by a factor of 0.1 every 10 epochs.\n",
    "\n",
    "When to use: Ideal for longer training runs where the model needs to converge smoothly.\n",
    "\"\"\"\n",
    "\n",
    "# Example optimizer (Adam in this case)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# StepLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                             step_size=10,   # Every 10 epochs, reduce learning rate\n",
    "                                             gamma=0.1)      # Multiply the learning rate by 0.1 after step_size epochs\n",
    "\n",
    "################################################\n",
    "################### ExponentialLR #####################\n",
    "################################################\n",
    "\"\"\"\n",
    "The learning rate decays exponentially based on the number of epochs. This type of scheduling reduces the learning rate at an exponentially decreasing rate, providing a smooth decay.\n",
    "\n",
    "When to use: Typically used in settings where you want gradual decay without abrupt changes.\n",
    "\"\"\"\n",
    "\n",
    "# ExponentialLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, \n",
    "                                                   gamma=0.99)  # Decay the learning rate by 1% after every epoch\n",
    "\n",
    "################################################\n",
    "############ CosineAnnealingLR  ################\n",
    "################################################\n",
    "\"\"\"\n",
    "The learning rate follows a cosine curve, gradually decaying to a minimum learning rate at the end of each cycle. It can also \"restart\" after completing a cycle.\n",
    "\n",
    "When to use: Great for training over many epochs (e.g., deep neural networks or large datasets) and allows for smoother decay. The cyclical nature helps avoid getting stuck in local minima.\n",
    "\"\"\"\n",
    "\n",
    "# CosineAnnealingLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                      T_max=50,    # Number of epochs after which learning rate reaches the minimum\n",
    "                                                      eta_min=1e-6) # The minimum learning rate value, which the scheduler will approach\n",
    "################################################\n",
    "############ ReduceLROnPlateau ################\n",
    "################################################\n",
    "\n",
    "\"\"\"\n",
    "The learning rate is reduced when a monitored metric (such as validation loss) stops improving. It adapts the learning rate dynamically based on model performance.\n",
    "\n",
    "When to use: Best for situations where you want to decrease the learning rate when the model plateaus. For example, if the validation loss stops improving for several epochs, the learning rate will decrease, often helping the model escape local minima.\n",
    "\"\"\"\n",
    "\n",
    "# ReduceLROnPlateau scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                      mode='min',   # 'min' means we reduce learning rate when validation loss is no longer decreasing\n",
    "                                                      factor=0.1,   # Reduce the learning rate by a factor of 0.1\n",
    "                                                      patience=5,   # Number of epochs to wait before reducing the learning rate\n",
    "                                                      verbose=True) # Print a message when learning rate is reduced\n",
    "\n",
    "################################################\n",
    "################# CyclicLR  ####################\n",
    "################################################\n",
    "\"\"\"\n",
    "The learning rate is cycled between a minimum and maximum value over multiple iterations, with the idea being to avoid getting stuck in local minima and speed up convergence.\n",
    "\n",
    "When to use: Best for training models where you want faster convergence and escape from local minima. Useful when you have long training cycles.\n",
    "\"\"\"\n",
    "\n",
    "# CyclicLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              base_lr=1e-6,    # Minimum learning rate\n",
    "                                              max_lr=0.1,      # Maximum learning rate\n",
    "                                              step_size_up=2000, # Number of iterations to increase the learning rate\n",
    "                                              mode='triangular')  # Triangular mode of learning rate increase/decrease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Warm-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Learning Rate Warm-up Works\n",
    "Learning rate warm-up is a technique used to gradually increase the learning rate from a small value to the target value over a set number of iterations or epochs at the beginning of training. This helps avoid large updates in the early stages, which can cause instability or poor convergence.\n",
    "\n",
    "Instead of starting with a high learning rate, warm-up starts small, allowing the model to make controlled, stable updates. Once the warm-up phase is complete, the learning rate reaches its target, and the model continues training with the chosen learning rate or a scheduled decay. This method ensures smoother and more stable training, especially for deep networks and large models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple model (e.g., a linear layer)\n",
    "model = torch.nn.Linear(10, 1)\n",
    "\n",
    "# Optimizer setup (using Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Initial learning rate (after warm-up phase)\n",
    "\n",
    "# Learning rate warm-up parameters\n",
    "warm_up_epochs = 5  # Number of epochs for the warm-up phase\n",
    "base_lr = 1e-6      # Starting learning rate during warm-up (start small to avoid instability)\n",
    "target_lr = 0.001   # Final learning rate after warm-up (typically your target learning rate)\n",
    "\n",
    "# Warm-up loop: gradually increase the learning rate from base_lr to target_lr\n",
    "for epoch in range(warm_up_epochs):\n",
    "    # Calculate the current learning rate for this epoch\n",
    "    lr = base_lr + (target_lr - base_lr) * (epoch + 1) / warm_up_epochs  # Linear increase\n",
    "    \"\"\"\n",
    "    The learning rate is gradually increased linearly from base_lr to target_lr. For each epoch during the warm-up phase, the learning rate is updated.\n",
    "    lr is calculated for each epoch by linearly interpolating between base_lr and target_lr.\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:  # Update optimizer's learning rate\n",
    "        param_group['lr'] = lr  # Set the new learning rate\n",
    "\n",
    "    # Explanation of parameters:\n",
    "    # base_lr: The initial learning rate at the start of warm-up (very small to start training gently)\n",
    "    # target_lr: The final learning rate after warm-up (the main learning rate that you intend to use)\n",
    "    # warm_up_epochs: The number of epochs to linearly increase the learning rate\n",
    "    # lr: The current learning rate, gradually increasing from base_lr to target_lr over the warm-up epochs\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}/{warm_up_epochs} | Learning Rate: {lr}')  # Print the current learning rate for each epoch\n",
    "\n",
    "# After warm-up, continue training with the main learning rate\n",
    "# You can use a scheduler or leave the learning rate constant if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Decay (L2 Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Weight Decay (L2 Regularization) is Needed\n",
    "Weight decay, also known as L2 regularization, is a technique used to prevent overfitting in machine learning models, especially deep learning models. It works by adding a penalty to the loss function based on the magnitude of the weights. This penalty discourages the model from learning overly large weights, which can cause the model to overfit to the training data.\n",
    "\n",
    "How It Works:\n",
    "During training, the optimizer updates the model's weights to minimize the loss function. Weight decay adds an extra term to the loss function that penalizes large weights, effectively shrinking them over time. This makes the model focus on simpler solutions rather than overfitting to the noise in the training data.\n",
    "\n",
    "Impact of Weight Decay:\n",
    "Prevents Overfitting: By adding a penalty for large weights, weight decay helps the model generalize better to unseen data.\n",
    "\n",
    "Simpler Models: Encourages the model to find solutions with smaller weights, leading to more robust and generalizable models.\n",
    "\n",
    "Stabilizes Training: Helps the optimizer focus on simpler solutions, preventing extreme weight values that could cause instability during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Gradient Clipping is Needed:\n",
    "Gradient clipping is a technique used to prevent the exploding gradient problem in deep learning models. This problem occurs when gradients become very large during backpropagation, leading to unstable training, where weights change dramatically in a single update, causing the model to diverge.\n",
    "\n",
    "Gradient clipping limits the gradients' values, ensuring they do not exceed a certain threshold. This helps stabilize the training process, especially in deep networks or RNNs where the gradients can become very large.\n",
    "\n",
    "How Gradient Clipping Works:\n",
    "During the backpropagation process, the gradients of the loss function with respect to the model's parameters are computed. If any gradient exceeds a predefined threshold, gradient clipping scales the gradients down so that they do not exceed this threshold, thus maintaining stability in the training process.\n",
    "\n",
    "Impact of Gradient Clipping:\n",
    "Prevents Exploding Gradients: By clipping large gradients, the model avoids drastic weight updates and keeps the training process stable.\n",
    "\n",
    "Improves Training Stability: It ensures that large gradients do not lead to unstable updates, which is especially useful in deep networks and RNNs.\n",
    "\n",
    "Allows Use of Larger Learning Rates: With gradient clipping, you can use larger learning rates without risking instability, improving training efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple model (e.g., a linear layer)\n",
    "model = torch.nn.Linear(10, 1)\n",
    "\n",
    "# Optimizer setup (using Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (example)\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()  # Zero out gradients from previous step\n",
    "    loss = some_loss_function(model, data, targets)  # Compute loss (assume loss function is defined)\n",
    "    \n",
    "    loss.backward()  # Backpropagate gradients\n",
    "    \n",
    "    # Gradient clipping to avoid exploding gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients if their norm exceeds 1.0\n",
    "    \n",
    "    optimizer.step()  # Update model parameters based on gradients\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/100 | Loss: {loss.item()}')\n",
    "\n",
    "# Explanation of the code:\n",
    "# clip_grad_norm_: Clamps the gradients during backpropagation if their norm exceeds the max_norm threshold.\n",
    "# max_norm: The threshold value for gradient clipping. Gradients are scaled down to this value if they exceed it.\n",
    "# optimizer.step(): After clipping, the optimizer uses the modified gradients to update the model's weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
